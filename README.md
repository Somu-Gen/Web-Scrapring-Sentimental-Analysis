# Web Scraping & Sentimental Analysis

Used libraries: Beautiful soup, requests, pandas, nltk tokenizer , Regex.

nltk module is very helpful in performing text cleaning and analysis.


This is a brief overview of the work-flow.

•	Extracted web data from given URL’s (Input.xlsx) into text files that are stored in Scrape_text_files folder.

•	With provided StopWords text ,new_StopWords are generated by  combining with inbuilt (English)Stopwords.

•	And MasterDictionary(positive & negative txt files) are cleaned by removing the stopwords from new_stopwords list.

•	Text is filtered and analysis is performed as per instructions given in Text Analysis.
